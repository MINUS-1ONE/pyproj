# 错误反向传播

原则上，反向传播提供了一种训练==具有任何数量的隐藏节点和隐藏层的网络==的方法（有明显的可行性限制，这个之后讨论）。事实上，网络不必分层组织——任何允许从输入到输出的过程对节点进行偏序连接模式都是可行的（？原文：the network does not have to be organized in layers - any pattern of connectivity that permits a partial ordering of the nodes from input to output is allowed.）换句话说，必须有一个方法对节点进行排序以使**所有连接都**从靠近输入层到靠近输出层，相当于说明其连接模式不能包含任何循环，遵循这种约束的网络称为**前馈**神经网络；他们的连接方式形成一个**directed acyclic graph** （无回路有向图，即我们经常见到的用于解释神经网络的图）

## 算法

我们想通过梯度下降训练一个多层前馈神经网络，来近似出一个未知的函数，基于一些由**(x,t)**数据对组成的训练数据集。向量**x**表示一种输入到网络的模式，向量**t**对应目标值（期望输出）。